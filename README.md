# DeepLearningStudy

딥러닝 공부하면서 실습한 파일 정리하는 곳

Deep Learning from Scratch 밑바닥부터 시작하는 딥러닝(사이토 고키, 한빛 미디어) 책 기반


******

### 최근 진행 내용

#### 2022-07-13
**Chapter5**\
5.6 ~ 5.8(p.170~p.187)
- Affine 계층 구현 : 입력값(배열)과 가중치, 편향을 계산하는 과정을 계층화하여 순전파와 역전파 구현
- 출력층 계층 구현 : 소프트맥스 함수(추론값을 정규화하는 함수), 교차 엔트로피 오차(정답값과 비교하는 손실 함수) 계산 과정을 계층화하여 순전파와 역전파 구현
- 수치 미분 대신 오차역전파법을 사용하는 신경망 구현
- 오차역전파법은 수치 미분보다 빠르지만 구현이 복잡하므로 구현에 오류가 없는지 수치 미분 방식을 같이 사용하여 기울기 값을 교차검증해야 함 : 기울기 확인
- 오차역전파법을 사용하여 신경망 학습 과정 구현


#### 2022-07-11
**Chapter5**\
5 ~ 5.5.2(p.147~p.170)
- 오차역전파법(역전파)을 통해 신경망 매개변수의 기울기를 더욱 효율적으로 계산 가능
- 계산 그래프 개념 및 설계 : 노드(계층)과 에지(직선)을 이용하여 계산 과정을 그래프로 그려 시각적으로 이해하기 쉽게 나타낸 것
- 계산 그래프 상에서의 순전파와 역전파 계산 과정 해석 및 설계
- 덧셈 노드의 역전파와 곱셈 노드의 역전파 계산법
- 덧셈 노드와 곱셈 노드를 계층화하여 순전파와 역전파 구현
- 활성화 함수(ReLU 함수, 시그모이드 함수)를 계층화하여 순전파와 역전파 구현

#### 2022-07-08
**Chapter4**\
4.5 ~ 4.6(p.136~p.146)
- 신경망 학습 절차 : 1단계(미니배치) - 2단계(기울기 산출) - 3단계(매개변수 갱신) - 4단계(1~3단계 반복)
- 확률적 경사 하강법 : 학습 데이터를 미니배치를 통해 무작위로 선정하여 매개변수를 갱신하는 경사 하강법
- 2층 신경망 클래스 구현 (매개변수를 딕셔너리로 저장하여 메소드를 통해 손실값, 정확도, 기울기를 구할 수 있음)
- 미니배치를 통한 2층 신경망 학습 구현
- 시험 데이터를 이용하여 훈련 데이터로 학습한 신경망의 범용 능력 평가



