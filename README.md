# DeepLearningStudy

딥러닝 공부하면서 실습한 파일 정리하는 곳

Deep Learning from Scratch 밑바닥부터 시작하는 딥러닝(사이토 고키, 한빛 미디어) 책 기반

역시 빡세군

******

### 최근 진행 내용

#### 2022-07-08
**Chapter4**\
4.5 ~ 4.6(p.136~p.146)
- 신경망 학습 절차 : 1단계(미니배치) - 2단계(기울기 산출) - 3단계(매개변수 갱신) - 4단계(1~3단계 반복)
- 확률적 경사 하강법 : 학습 데이터를 미니배치를 통해 무작위로 선정하여 매개변수를 갱신하는 경사 하강법
- 2층 신경망 클래스 구현 (매개변수를 딕셔너리로 저장하여 메소드를 통해 손실값, 정확도, 기울기를 구할 수 있음)
- 미니배치를 통한 2층 신경망 학습 구현
- 시험 데이터를 이용하여 훈련 데이터로 학습한 신경망의 범용 능력 평가

#### 2022-07-06
**Chapter4**\
4.3.3(p.127~p.136)
- 기울기 : 모든 변수의 편미분을 벡터로 정리한 것
- 기울기 구현(입력한 모든 변수(배열)의 편미분 값을 해당되는 크기의 배열로 나타냄)
- 기울기의 역할은 각 위치(현재 x 입력값)에서 함수의 출력값을 최소화할 수 있는 값으로의 방향을 가리키는 것
- 경사법 : 최초 입력값에서 기울기가 가리키는 방향으로 일정지점 이동하여 함수값이 최소가 되는 지점을 찾아 일정한 거리를 이동하며 추적하는 과정을 반복하는 것
- 경사법 구현 (대상 함수와 초기 입력값, 학습률, 반복 횟수 설정)
- 신경망 학습은 손실함수 결과값이 최소가 되도록 하는 가중치 매개변수를 기울기를 이용하여 찾아가는 과정

#### 2022-07-05
**Chapter4**\
4.3.3(p.125~p.127)
- 편미분 : 입력값(변수)이 2개 이상인 함수에 대한 미분
- 편미분 미분 구현(목표 변수 이외의 변수를 상수(고정된 값)로 바꾸어 변수가 하나인 함수를 만들고 그 함수를 미분)


#### 2022-07-03
**Chapter4**\
4.2.2 ~ 4.3.2(p.113~p.125)
- 교차 엔트로피 오차 함수(손실함수) 구현
- 미니배치 학습 : 방대한 양의 데이터들을 학습해야 할 때 데이터들의 일부(미니배치)를 무작위로 골라 학습하는 방법
- 데이터를 미니배치(단일 데이터가 아닌 일정 데이터 묶음)로 입력받을 때의 손실함수 구현
- 손실함수(그리고 활성화함수로 소프트맥스 함수)를 사용하는 이유는 매개변수의 사소한 변화로 인한 결과 값의 사소한 변화를 포착하여 학습 성능을 높이기 위함
- 수치 미분의 기본적인 개념 및 구현


#### 2022-07-02
**Chapter4**\
4.1 ~ 4.2.1(p.107~p.113)
- 딥러닝을 비롯한 기계학습은 데이터를 이용하여 학습
- 딥러닝은 데이터를 입력받은 후 사람의 개입없이 추정 결과까지의 모든 과정을 컴퓨터가 스스로 학습 및 판단
- 기계학습을 진행할 때 학습 데이터를 '훈련 데이터'와 '시험 데이터'로 이원화하는 과정 필요(특정 데이터에만 편향적이지 않도록 범용성을 가지기 위함)
- 손실함수를 통해 신경망이 추정한 결과와 실제 정답을 비교하여 신경망이 얼마나 정확한지 판정
- 오차제곱합 함수(손실함수) 구현






